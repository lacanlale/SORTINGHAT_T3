{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "dict_label = {\n",
    "    'Datetime':0, \n",
    "    'Sentence':1, \n",
    "    'Custom Object': 2, \n",
    "    'URL': 3, \n",
    "    'Numbers': 4, \n",
    "    'List': 5}\n",
    "data = pd.read_csv('data/needs_extraction_data/labelled_data.csv')\n",
    "\n",
    "data['y_act'] = [dict_label[i] for i in data['y_act']]\n",
    "y = data.loc[:,['y_act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Data mean: scaled_perc_nans             -2.745801e-16\n",
      "scaled_mean_token_count      -1.117919e-16\n",
      "scaled_std_dev_token_count   -2.236863e-17\n",
      "has_delimiters                3.105360e-01\n",
      "dtype: float64\n",
      "> Data median: scaled_perc_nans             -0.653046\n",
      "scaled_mean_token_count      -0.144106\n",
      "scaled_std_dev_token_count   -0.171320\n",
      "has_delimiters                0.000000\n",
      "dtype: float64\n",
      "> Data stdev: scaled_perc_nans              1.000925\n",
      "scaled_mean_token_count       1.000925\n",
      "scaled_std_dev_token_count    1.000925\n",
      "has_delimiters                0.463141\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data1 = data[['%_nans', 'mean_word_count', 'std_dev_word_count', 'has_delimiters']]\n",
    "data1 = data1.fillna(0)\n",
    "\n",
    "data1 = data1.rename(columns={'mean_word_count': 'scaled_mean_token_count', 'std_dev_word_count': 'scaled_std_dev_token_count', '%_nans': 'scaled_perc_nans'})\n",
    "data1.loc[data1['scaled_mean_token_count'] > 10000, 'scaled_mean_token_count'] = 10000\n",
    "data1.loc[data1['scaled_mean_token_count'] < -10000, 'scaled_mean_token_count'] = -10000\n",
    "data1.loc[data1['scaled_std_dev_token_count'] > 10000, 'scaled_std_dev_token_count'] = 10000\n",
    "data1.loc[data1['scaled_std_dev_token_count'] < -10000, 'scaled_std_dev_token_count'] = -10000\n",
    "data1.loc[data1['scaled_perc_nans'] > 10000, 'scaled_perc_nans'] = 10000\n",
    "data1.loc[data1['scaled_perc_nans'] < -10000, 'scaled_perc_nans'] = -10000\n",
    "column_names_to_normalize = ['scaled_mean_token_count', 'scaled_std_dev_token_count','scaled_perc_nans']\n",
    "x = data1[column_names_to_normalize].values\n",
    "x = np.nan_to_num(x)\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = data1.index)\n",
    "data1[column_names_to_normalize] = df_temp\n",
    "\n",
    "y.y_act = y.y_act.astype(float)\n",
    "\n",
    "print(f\"> Data mean: {data1.mean()}\")\n",
    "print(f\"> Data median: {data1.median()}\")\n",
    "print(f\"> Data stdev: {data1.std()}\")\n",
    "\n",
    "# data1.to_csv('before.csv')\n",
    "# f = open('current.txt','w')\n",
    "# d = enchant.Dict(\"en_US\")\n",
    "\n",
    "# for i in data.index:\n",
    "#     ival = data.at[i,'Attribute_name']\n",
    "#     if ival != 'id' and d.check(ivadf_tempdata1)\n",
    "#         print(f,ival)\n",
    "#         print(f,y.at[i,'y_act'])\n",
    "#         data1.at[i,'dictionary_item'] = 1\n",
    "#     else:\n",
    "#         data1.at[i,'dictionary_item'] = 0\n",
    "\n",
    "# data1.to_csv('after.csv')\n",
    "# f.close()\n",
    "# print(data1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===[VECTORIZATION]===\n",
      "> Length of vectorized feature_names: 8528\n",
      "X_train preview:      scaled_perc_nans  scaled_mean_token_count  scaled_std_dev_token_count  \\\n",
      "453         -0.653097                 0.686283                    3.364514   \n",
      "43          -0.653120                 0.162079                   -0.054513   \n",
      "133          1.978459                -0.148544                   -0.167108   \n",
      "205         -0.653120                -0.141062                   -0.175870   \n",
      "282         -0.653120                -0.148960                   -0.175870   \n",
      "\n",
      "     has_delimiters  0  1  2  3  4  5  ...   8518  8519  8520  8521  8522  \\\n",
      "453            True  0  0  0  0  0  0  ...      0     0     0     0     0   \n",
      "43             True  0  0  0  0  0  0  ...      0     0     0     0     0   \n",
      "133            True  0  0  0  0  0  0  ...      0     0     0     0     0   \n",
      "205           False  0  0  0  0  0  0  ...      0     0     0     0     0   \n",
      "282           False  0  0  0  0  0  0  ...      0     0     0     0     0   \n",
      "\n",
      "     8523  8524  8525  8526  8527  \n",
      "453     0     0     0     0     0  \n",
      "43      0     0     0     0     0  \n",
      "133     0     0     0     0     0  \n",
      "205     0     0     0     0     0  \n",
      "282     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 18519 columns]\n",
      "y_train preview:      y_act\n",
      "453    1.0\n",
      "43     1.0\n",
      "133    2.0\n",
      "205    0.0\n",
      "282    0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"===[VECTORIZATION]===\")\n",
    "arr = data['Attribute_name'].values\n",
    "data = data.fillna(0)\n",
    "arr1 = data['sample_1'].values\n",
    "arr1 = [str(x) for x in arr1]\n",
    "arr2 = data['sample_2'].values\n",
    "arr2 = [str(x) for x in arr2]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(3, 3), analyzer='char')\n",
    "X = vectorizer.fit_transform(arr)\n",
    "X1 = vectorizer.fit_transform(arr1)\n",
    "X2 = vectorizer.fit_transform(arr2)\n",
    "\n",
    "print(f\"> Length of vectorized feature_names: {len(vectorizer.get_feature_names())}\")\n",
    "\n",
    "data1.to_csv('data/preprocessing/before.csv')\n",
    "attr_df = pd.DataFrame(X.toarray())\n",
    "sample1_df = pd.DataFrame(X1.toarray())\n",
    "sample2_df = pd.DataFrame(X2.toarray())\n",
    "\n",
    "data2 = pd.concat([data1, attr_df, sample1_df, sample2_df], axis=1, sort=False)\n",
    "data2.to_csv('data/preprocessing/after.csv')\n",
    "data2.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data2, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# X_train_train, X_test_train,y_train_train,y_test_train = train_test_split(X_train,y_train, test_size=0.25)\n",
    "# print(X_train.head())\n",
    "# print(y_train.head())\n",
    "\n",
    "X_train_new = X_train.reset_index(drop=True)\n",
    "y_train_new = y_train.reset_index(drop=True)\n",
    "print(f\"X_train preview: {X_train.head()}\")\n",
    "print(f\"y_train preview: {y_train.head()}\")\n",
    "\n",
    "X_train_new = X_train_new.values\n",
    "y_train_new = y_train_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    acc_df = pd.read_csv('data/model_data.csv')\n",
    "    index = len(acc_df)\n",
    "except FileNotFoundError:\n",
    "    acc_df = pd.DataFrame(columns=['Model', 'Params', 'Feats', 'Train', 'Validation', 'Test', 'Precision'])\n",
    "    index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 0.0001, accuracy: 0.47126436781609193]\n",
      "[C: 0.001, accuracy: 0.4827586206896552]\n",
      "[C: 0.01, accuracy: 0.6896551724137931]\n",
      "[C: 0.1, accuracy: 0.7701149425287356]\n",
      "[C: 1, accuracy: 0.8045977011494253]\n",
      "[C: 10, accuracy: 0.8045977011494253]\n",
      "[C: 100, accuracy: 0.8275862068965517]\n",
      "[C: 1000, accuracy: 0.8160919540229885]\n",
      "[C: 10000, accuracy: 0.8275862068965517]\n",
      "[C: 100000, accuracy: 0.8390804597701149]\n",
      "\n",
      "> Best C: 100000\n",
      "> Best training score: 0.9594202898550724\n",
      "> Best test score: 0.7816091954022989\n",
      "> Best held score: 0.7798165137614679\n",
      "==========\n",
      "[C: 0.0001, accuracy: 0.4482758620689655]\n",
      "[C: 0.001, accuracy: 0.47126436781609193]\n",
      "[C: 0.01, accuracy: 0.6436781609195402]\n",
      "[C: 0.1, accuracy: 0.7011494252873564]\n",
      "[C: 1, accuracy: 0.7126436781609196]\n",
      "[C: 10, accuracy: 0.7241379310344828]\n",
      "[C: 100, accuracy: 0.7241379310344828]\n",
      "[C: 1000, accuracy: 0.7241379310344828]\n",
      "[C: 10000, accuracy: 0.7241379310344828]\n",
      "[C: 100000, accuracy: 0.7241379310344828]\n",
      "\n",
      "> Best C: 10\n",
      "> Best training score: 0.9304347826086956\n",
      "> Best test score: 0.8160919540229885\n",
      "> Best held score: 0.8440366972477065\n",
      "==========\n",
      "[C: 0.0001, accuracy: 0.45977011494252873]\n",
      "[C: 0.001, accuracy: 0.47126436781609193]\n",
      "[C: 0.01, accuracy: 0.6781609195402298]\n",
      "[C: 0.1, accuracy: 0.735632183908046]\n",
      "[C: 1, accuracy: 0.7471264367816092]\n",
      "[C: 10, accuracy: 0.7011494252873564]\n",
      "[C: 100, accuracy: 0.7011494252873564]\n",
      "[C: 1000, accuracy: 0.6666666666666666]\n",
      "[C: 10000, accuracy: 0.6666666666666666]\n",
      "[C: 100000, accuracy: 0.6436781609195402]\n",
      "\n",
      "> Best C: 1\n",
      "> Best training score: 0.930635838150289\n",
      "> Best test score: 0.8488372093023255\n",
      "> Best held score: 0.8256880733944955\n",
      "==========\n",
      "[C: 0.0001, accuracy: 0.5287356321839081]\n",
      "[C: 0.001, accuracy: 0.5402298850574713]\n",
      "[C: 0.01, accuracy: 0.7586206896551724]\n",
      "[C: 0.1, accuracy: 0.7701149425287356]\n",
      "[C: 1, accuracy: 0.8160919540229885]\n",
      "[C: 10, accuracy: 0.7816091954022989]\n",
      "[C: 100, accuracy: 0.7471264367816092]\n",
      "[C: 1000, accuracy: 0.7471264367816092]\n",
      "[C: 10000, accuracy: 0.7471264367816092]\n",
      "[C: 100000, accuracy: 0.7471264367816092]\n",
      "\n",
      "> Best C: 1\n",
      "> Best training score: 0.9479768786127167\n",
      "> Best test score: 0.7790697674418605\n",
      "> Best held score: 0.8073394495412844\n",
      "==========\n",
      "[C: 0.0001, accuracy: 0.5632183908045977]\n",
      "[C: 0.001, accuracy: 0.5977011494252874]\n",
      "[C: 0.01, accuracy: 0.7471264367816092]\n",
      "[C: 0.1, accuracy: 0.7931034482758621]\n",
      "[C: 1, accuracy: 0.8275862068965517]\n",
      "[C: 10, accuracy: 0.7586206896551724]\n",
      "[C: 100, accuracy: 0.7471264367816092]\n",
      "[C: 1000, accuracy: 0.7471264367816092]\n",
      "[C: 10000, accuracy: 0.7471264367816092]\n",
      "[C: 100000, accuracy: 0.7471264367816092]\n",
      "\n",
      "> Best C: 1\n",
      "> Best training score: 0.9508670520231214\n",
      "> Best test score: 0.8023255813953488\n",
      "> Best held score: 0.8073394495412844\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "avg_train_acc, avg_test_acc = 0, 0\n",
    "\n",
    "val_arr = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "\n",
    "avgsc_lst, avgsc_train_lst, avgsc_hld_lst = [], [], []\n",
    "avgsc, avgsc_train, avgsc_hld = 0, 0, 0\n",
    "\n",
    "best_param_count = {'cval': {}}\n",
    "for train_index, test_index in kf.split(X_train_new):\n",
    "    X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "    y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "    X_train_train, X_val, y_train_train, y_val = train_test_split(\n",
    "        X_train_cur, y_train_cur, test_size=0.25, random_state=100)\n",
    "\n",
    "    bestPerformingModel = LogisticRegression(\n",
    "        penalty='l2', multi_class='multinomial', solver='lbfgs', C=1)\n",
    "    bestscore = 0\n",
    "    print('='*10)\n",
    "    for val in val_arr:\n",
    "        clf = LogisticRegression(\n",
    "            penalty='l2', multi_class='multinomial', solver='lbfgs', C=val)\n",
    "        clf.fit(X_train_train, y_train_train)\n",
    "        sc = clf.score(X_val, y_val)\n",
    "        print(f\"[C: {val}, accuracy: {sc}]\")\n",
    "        if bestscore < sc:\n",
    "            bestcval = val\n",
    "            bestscore = sc\n",
    "            bestPerformingModel = clf\n",
    "    \n",
    "    if str(bestcval) in best_param_count['cval']:\n",
    "        best_param_count['cval'][str(bestcval)] += 1\n",
    "    else:\n",
    "        best_param_count['cval'][str(bestcval)] = 1\n",
    "        \n",
    "    bscr_train = bestPerformingModel.score(X_train_cur, y_train_cur)\n",
    "    bscr = bestPerformingModel.score(X_test_cur, y_test_cur)\n",
    "    bscr_hld = bestPerformingModel.score(X_test, y_test)\n",
    "\n",
    "    avgsc_train_lst.append(bscr_train)\n",
    "    avgsc_lst.append(bscr)\n",
    "    avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "    avgsc_train = avgsc_train + bscr_train\n",
    "    avgsc = avgsc + bscr\n",
    "    avgsc_hld = avgsc_hld + bscr_hld\n",
    "    print()\n",
    "    print(f\"> Best C: {bestcval}\")\n",
    "    print(f\"> Best training score: {bscr_train}\")\n",
    "    print(f\"> Best test score: {bscr}\")\n",
    "    print(f\"> Best held score: {bscr_hld}\")\n",
    "print('='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestPerformingModel.predict(X_test)\n",
    "prec = metrics.precision_score(y_test, y_pred, average=None)\n",
    "cat_prec = {\n",
    "    'Datetime': prec[0],\n",
    "    'Sentence': prec[1],\n",
    "    'Custom Object': prec[2],\n",
    "    'URL': prec[3],\n",
    "    'Numbers': prec[4],\n",
    "    'List': prec[5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Best C param : 1\n",
      "> Average training score list: [0.9594202898550724, 0.9304347826086956, 0.930635838150289, 0.9479768786127167, 0.9508670520231214]\n",
      "> Average testing score list: [0.7816091954022989, 0.8160919540229885, 0.8488372093023255, 0.7790697674418605, 0.8023255813953488]\n",
      "> Average held score list: [0.7798165137614679, 0.8440366972477065, 0.8256880733944955, 0.8073394495412844, 0.8073394495412844]\n",
      "\n",
      "> Average training score list: 0.9438669682499791\n",
      "> Average testing score list: 0.8055867415129645\n",
      "> Average held score list: 0.8128440366972477\n",
      "\n",
      "Confusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "[[24  0  3  0  0  0]\n",
      " [ 0 13  9  0  0  0]\n",
      " [ 1  1 49  0  0  1]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  1  3  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "bestcval = max(best_param_count['cval'], key=lambda i: best_param_count['cval'][i])\n",
    "bestparams = {'C': bestcval}\n",
    "print(f\"> Best C param : {bestcval}\")\n",
    "print(f\"> Average training score list: {avgsc_train_lst}\")\n",
    "print(f\"> Average testing score list: {avgsc_lst}\")\n",
    "print(f\"> Average held score list: {avgsc_hld_lst}\")\n",
    "print()\n",
    "avgsc_train = avgsc_train/k\n",
    "avgsc = avgsc/k\n",
    "avgsc_hld = avgsc_hld/k\n",
    "print(f\"> Average training score list: {avgsc_train}\")\n",
    "print(f\"> Average testing score list: {avgsc}\")\n",
    "print(f\"> Average held score list: {avgsc_hld}\")\n",
    "acc_df.loc[index] = ['logistic_regression', str(bestparams),\"X_stats, X_name, X_sample1, X_sample2\", avgsc_train, avgsc, avgsc_hld, str(cat_prec)]\n",
    "index += 1\n",
    "print()\n",
    "\n",
    "y_pred = bestPerformingModel.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix: Actual (Row) vs Predicted (Column)')\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0         1             2             3             4  \\\n",
      "0    1.774810e-01  0.111524  5.616456e-01  1.653244e-02  9.958602e-02   \n",
      "1    1.647054e-05  0.000145  2.566129e-05  9.997353e-01  2.914670e-05   \n",
      "2    9.951246e-01  0.000891  2.016093e-03  3.281248e-04  8.957817e-04   \n",
      "3    9.746274e-01  0.003230  1.247266e-02  1.162901e-03  5.810947e-03   \n",
      "4    1.584281e-01  0.102213  5.345663e-01  1.670232e-02  1.152096e-01   \n",
      "5    2.496679e-01  0.026481  7.021329e-01  1.959321e-03  1.653270e-02   \n",
      "6    5.423825e-03  0.005053  9.805596e-01  5.396741e-04  7.472988e-03   \n",
      "7    9.961150e-01  0.000748  1.546386e-03  2.653828e-04  7.761667e-04   \n",
      "8    8.982853e-01  0.015375  3.939505e-02  4.148656e-03  3.151666e-02   \n",
      "9    4.791981e-02  0.410763  4.899998e-01  8.017798e-03  1.846321e-02   \n",
      "10   2.988086e-01  0.042995  5.257421e-01  1.169134e-02  6.983392e-02   \n",
      "11   1.401693e-02  0.800999  1.609837e-01  3.502841e-03  4.021134e-03   \n",
      "12   9.989725e-01  0.000128  4.012316e-04  7.937463e-05  2.757507e-04   \n",
      "13   9.826765e-01  0.002315  8.323324e-03  1.006969e-03  3.483847e-03   \n",
      "14   2.216800e-01  0.098387  4.771067e-01  1.763798e-02  1.497913e-01   \n",
      "15   2.585930e-01  0.043878  6.121538e-01  7.474371e-03  5.802765e-02   \n",
      "16   1.365129e-16  1.000000  8.638903e-09  5.782292e-11  7.959103e-15   \n",
      "17   1.459947e-01  0.082579  6.437976e-01  9.920771e-03  8.462729e-02   \n",
      "18   1.274194e-01  0.137261  5.904599e-01  1.022697e-02  1.046849e-01   \n",
      "19   1.656647e-01  0.323242  3.431377e-01  1.426933e-02  1.112333e-01   \n",
      "20   1.992277e-01  0.067910  5.811137e-01  1.146873e-02  1.141733e-01   \n",
      "21   3.431595e-01  0.062149  3.899018e-01  1.380044e-02  1.575791e-01   \n",
      "22   4.853380e-16  0.999998  2.000763e-06  4.784525e-10  1.153879e-14   \n",
      "23   9.741901e-01  0.002248  1.735819e-02  8.583984e-04  3.076125e-03   \n",
      "24   1.546351e-01  0.059689  7.507552e-01  2.835110e-03  2.669830e-02   \n",
      "25   1.221767e-01  0.037846  7.385411e-01  1.874516e-02  6.256082e-02   \n",
      "26   2.154109e-01  0.419474  2.746220e-01  9.253747e-03  5.612694e-02   \n",
      "27   3.356377e-02  0.034542  8.780794e-01  2.233873e-03  4.740514e-02   \n",
      "28   9.995647e-01  0.000045  2.264835e-04  3.167107e-05  4.498082e-05   \n",
      "29   9.537609e-01  0.005121  1.522992e-02  1.741966e-03  2.068207e-02   \n",
      "..            ...       ...           ...           ...           ...   \n",
      "79   8.721155e-01  0.010701  5.374258e-02  3.454999e-03  5.107090e-02   \n",
      "80   1.773441e-01  0.108939  5.713961e-01  1.266483e-02  1.001169e-01   \n",
      "81   1.111190e-01  0.050494  5.767439e-01  7.584481e-03  2.381311e-01   \n",
      "82   1.829496e-02  0.007682  9.577269e-01  1.756134e-03  9.147377e-03   \n",
      "83   9.604406e-01  0.004500  1.292504e-02  1.544714e-03  1.753088e-02   \n",
      "84   2.099463e-01  0.074953  5.545667e-01  2.968017e-02  8.770938e-02   \n",
      "85   1.036427e-01  0.035981  8.180820e-01  4.576921e-03  2.467902e-02   \n",
      "86   1.339857e-01  0.359532  3.887011e-01  9.208985e-03  3.539660e-02   \n",
      "87   1.056910e-01  0.032763  7.854834e-01  5.859255e-03  5.422972e-02   \n",
      "88   1.260661e-02  0.970793  7.606569e-03  1.227409e-03  4.334801e-03   \n",
      "89   2.334757e-02  0.110746  8.332326e-01  4.630328e-03  2.074074e-02   \n",
      "90   6.653320e-01  0.013895  2.580537e-01  5.882340e-03  4.732675e-02   \n",
      "91   9.170283e-01  0.008451  5.531546e-02  1.815622e-03  1.362315e-02   \n",
      "92   6.190026e-02  0.066532  7.699598e-01  6.599823e-03  2.029071e-02   \n",
      "93   6.339977e-02  0.079578  7.407871e-01  6.646023e-03  8.333608e-02   \n",
      "94   2.082289e-01  0.074638  6.130527e-01  8.977453e-03  7.007181e-02   \n",
      "95   2.637358e-01  0.059478  4.497737e-01  1.274820e-02  1.815236e-01   \n",
      "96   1.327023e-01  0.058338  6.670253e-01  8.088644e-03  1.090066e-01   \n",
      "97   2.570071e-02  0.108059  7.812485e-01  3.841263e-02  2.092140e-02   \n",
      "98   3.695419e-03  0.001781  9.880387e-01  6.190256e-04  3.810375e-03   \n",
      "99   2.142317e-02  0.891208  7.226382e-02  1.884602e-03  4.305656e-03   \n",
      "100  9.784715e-01  0.004156  8.599390e-03  1.131764e-03  5.300955e-03   \n",
      "101  1.802921e-02  0.015524  5.399449e-02  8.866085e-01  1.444862e-02   \n",
      "102  5.578215e-03  0.005113  9.801517e-01  5.501045e-04  7.637009e-03   \n",
      "103  8.560191e-03  0.004756  9.779475e-01  5.227084e-04  7.085920e-03   \n",
      "104  6.272651e-02  0.292460  5.711511e-01  7.613693e-03  1.932354e-02   \n",
      "105  4.902515e-02  0.488318  3.724765e-01  1.411327e-02  2.198202e-02   \n",
      "106  4.513898e-03  0.002800  9.874732e-01  3.894685e-04  4.166047e-03   \n",
      "107  9.733868e-01  0.004310  1.213625e-02  1.379138e-03  5.663564e-03   \n",
      "108  4.866700e-03  0.004515  9.826129e-01  4.927650e-04  6.646809e-03   \n",
      "\n",
      "                5  \n",
      "0    3.323133e-02  \n",
      "1    4.831485e-05  \n",
      "2    7.448157e-04  \n",
      "3    2.696610e-03  \n",
      "4    7.288051e-02  \n",
      "5    3.226200e-03  \n",
      "6    9.510065e-04  \n",
      "7    5.488086e-04  \n",
      "8    1.127939e-02  \n",
      "9    2.483673e-02  \n",
      "10   5.092916e-02  \n",
      "11   1.647642e-02  \n",
      "12   1.428676e-04  \n",
      "13   2.194644e-03  \n",
      "14   3.539699e-02  \n",
      "15   1.987364e-02  \n",
      "16   1.442672e-10  \n",
      "17   3.308023e-02  \n",
      "18   2.994791e-02  \n",
      "19   4.245328e-02  \n",
      "20   2.610653e-02  \n",
      "21   3.341055e-02  \n",
      "22   3.471177e-09  \n",
      "23   2.268703e-03  \n",
      "24   5.387430e-03  \n",
      "25   2.013042e-02  \n",
      "26   2.511223e-02  \n",
      "27   4.175441e-03  \n",
      "28   8.709664e-05  \n",
      "29   3.463672e-03  \n",
      "..            ...  \n",
      "79   8.915271e-03  \n",
      "80   2.953874e-02  \n",
      "81   1.592766e-02  \n",
      "82   5.392821e-03  \n",
      "83   3.058320e-03  \n",
      "84   4.314400e-02  \n",
      "85   1.303872e-02  \n",
      "86   7.317567e-02  \n",
      "87   1.597398e-02  \n",
      "88   3.431696e-03  \n",
      "89   7.302406e-03  \n",
      "90   9.510164e-03  \n",
      "91   3.766242e-03  \n",
      "92   7.471693e-02  \n",
      "93   2.625279e-02  \n",
      "94   2.503065e-02  \n",
      "95   3.274020e-02  \n",
      "96   2.483929e-02  \n",
      "97   2.565754e-02  \n",
      "98   2.055313e-03  \n",
      "99   8.915152e-03  \n",
      "100  2.340875e-03  \n",
      "101  1.139519e-02  \n",
      "102  9.704927e-04  \n",
      "103  1.128036e-03  \n",
      "104  4.672516e-02  \n",
      "105  5.408527e-02  \n",
      "106  6.575947e-04  \n",
      "107  3.124119e-03  \n",
      "108  8.658440e-04  \n",
      "\n",
      "[109 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'data/pretrained/lr_finalized_model.pickle'\n",
    "pickle.dump(bestPerformingModel, open(filename, 'wb+'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb+'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "y_prob = bestPerformingModel.predict_proba(X_test)\n",
    "\n",
    "df = pd.DataFrame.from_records(y_prob)\n",
    "print(df)\n",
    "df.to_csv('data/model_predictions/lr_predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature combination testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feat_combos(index):\n",
    "    combos = {\n",
    "        \"X_stats\": data1,\n",
    "        \"X_name\": attr_df,\n",
    "        \"X_stats, X_name\": pd.concat([data1, attr_df], axis=1, sort=False),\n",
    "        \"X_sample1\":  pd.concat([sample1_df], axis=1, sort=False),\n",
    "        \"X_name, X_sample1\":  pd.concat([attr_df, sample1_df], axis=1, sort=False),\n",
    "        \"X_stats, X_sample1\":  pd.concat([data1, sample1_df], axis=1, sort=False),\n",
    "        \"X_stats, X_name, X_sample1\":  pd.concat([data1, attr_df, sample1_df], axis=1, sort=False)\n",
    "    }\n",
    "    \n",
    "\n",
    "    for combo in combos:\n",
    "        print(\"=\"*50, combo, \"=\"*50)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            combos[combo], y, test_size=0.2, random_state=100)\n",
    "\n",
    "        X_train_new = X_train.reset_index(drop=True)\n",
    "        y_train_new = y_train.reset_index(drop=True)\n",
    "        X_train_new = X_train_new.values\n",
    "        y_train_new = y_train_new.values\n",
    "        best_param_count = {'cval': {}}\n",
    "        k = 5\n",
    "        kf = KFold(n_splits=k)\n",
    "        avg_train_acc, avg_test_acc = 0, 0\n",
    "\n",
    "        val_arr = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "\n",
    "        avgsc_lst, avgsc_train_lst, avgsc_hld_lst = [], [], []\n",
    "        avgsc, avgsc_train, avgsc_hld = 0, 0, 0\n",
    "\n",
    "        best_param_count = {'cval': {}}\n",
    "        for train_index, test_index in kf.split(X_train_new):\n",
    "            X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "            y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "            X_train_train, X_val, y_train_train, y_val = train_test_split(\n",
    "                X_train_cur, y_train_cur, test_size=0.25, random_state=100)\n",
    "\n",
    "            bestPerformingModel = LogisticRegression(\n",
    "                penalty='l2', multi_class='multinomial', solver='lbfgs', C=1)\n",
    "            bestscore = 0\n",
    "            print('\\t', '-'*10)\n",
    "            for val in val_arr:\n",
    "                clf = LogisticRegression(\n",
    "                    penalty='l2', multi_class='multinomial', solver='lbfgs', C=val)\n",
    "                clf.fit(X_train_train, y_train_train)\n",
    "                sc = clf.score(X_val, y_val)\n",
    "                print(f\"\\t[C: {val}, accuracy: {sc}]\")\n",
    "                if bestscore < sc:\n",
    "                    bestcval = val\n",
    "                    bestscore = sc\n",
    "                    bestPerformingModel = clf\n",
    "\n",
    "            if str(bestcval) in best_param_count['cval']:\n",
    "                best_param_count['cval'][str(bestcval)] += 1\n",
    "            else:\n",
    "                best_param_count['cval'][str(bestcval)] = 1\n",
    "            bscr_train = bestPerformingModel.score(X_train_cur, y_train_cur)\n",
    "            bscr = bestPerformingModel.score(X_test_cur, y_test_cur)\n",
    "            bscr_hld = bestPerformingModel.score(X_test, y_test)\n",
    "\n",
    "            avgsc_train_lst.append(bscr_train)\n",
    "            avgsc_lst.append(bscr)\n",
    "            avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "            avgsc_train = avgsc_train + bscr_train\n",
    "            avgsc = avgsc + bscr\n",
    "            avgsc_hld = avgsc_hld + bscr_hld\n",
    "            print()\n",
    "            print(f\"\\t> Best C: {bestcval}\")\n",
    "            print(f\"\\t> Best training score: {bscr_train}\")\n",
    "            print(f\"\\t> Best test score: {bscr}\")\n",
    "            print(f\"\\t> Best held score: {bscr_hld}\")\n",
    "        print('\\t', '-'*10)\n",
    "        \n",
    "        y_pred = bestPerformingModel.predict(X_test)\n",
    "        prec = metrics.precision_score(y_test, y_pred, average=None)\n",
    "        cat_prec = {\n",
    "            'Datetime': prec[0],\n",
    "            'Sentence': prec[1],\n",
    "            'Custom Object': prec[2],\n",
    "            'URL': prec[3],\n",
    "            'Numbers': prec[4],\n",
    "            'List': prec[5],\n",
    "        }    \n",
    "        bestcval = max(best_param_count['cval'], key=lambda i: best_param_count['cval'][i])\n",
    "        bestparams = {'C': bestcval}\n",
    "        print(f\"\\t> Best C param : {bestcval}\")\n",
    "        print(f\"\\t> Average training score list: {avgsc_train_lst}\")\n",
    "        print(f\"\\t> Average testing score list: {avgsc_lst}\")\n",
    "        print(f\"\\t> Average held score list: {avgsc_hld_lst}\")\n",
    "        print()\n",
    "        avgsc_train = avgsc_train/k\n",
    "        avgsc = avgsc/k\n",
    "        avgsc_hld = avgsc_hld/k\n",
    "        print(f\"\\t> Average training score list: {avgsc_train}\")\n",
    "        print(f\"\\t> Average testing score list: {avgsc}\")\n",
    "        print(f\"\\t> Average held score list: {avgsc_hld}\")\n",
    "        acc_df.loc[index] = ['logistic_regression', str(bestparams), combo, avgsc_train, avgsc, avgsc_hld, str(cat_prec)]\n",
    "        index += 1\n",
    "        print()\n",
    "\n",
    "        y_pred = bestPerformingModel.predict(X_test)\n",
    "        cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "        print('\\tConfusion Matrix: Actual (Row) vs Predicted (Column)')\n",
    "        print('\\t', cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== X_stats ==================================================\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.01, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.1, accuracy: 0.5402298850574713]\n",
      "\t[C: 1, accuracy: 0.5287356321839081]\n",
      "\t[C: 10, accuracy: 0.5517241379310345]\n",
      "\t[C: 100, accuracy: 0.6206896551724138]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[C: 1000, accuracy: 0.7241379310344828]\n",
      "\t[C: 10000, accuracy: 0.7471264367816092]\n",
      "\t[C: 100000, accuracy: 0.7586206896551724]\n",
      "\n",
      "\t> Best C: 100000\n",
      "\t> Best training score: 0.7304347826086957\n",
      "\t> Best test score: 0.6551724137931034\n",
      "\t> Best held score: 0.7247706422018348\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.41379310344827586]\n",
      "\t[C: 0.001, accuracy: 0.41379310344827586]\n",
      "\t[C: 0.01, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.1, accuracy: 0.45977011494252873]\n",
      "\t[C: 1, accuracy: 0.47126436781609193]\n",
      "\t[C: 10, accuracy: 0.4942528735632184]\n",
      "\t[C: 100, accuracy: 0.5402298850574713]\n",
      "\t[C: 1000, accuracy: 0.6206896551724138]\n",
      "\t[C: 10000, accuracy: 0.6551724137931034]\n",
      "\t[C: 100000, accuracy: 0.6436781609195402]\n",
      "\n",
      "\t> Best C: 10000\n",
      "\t> Best training score: 0.672463768115942\n",
      "\t> Best test score: 0.6781609195402298\n",
      "\t> Best held score: 0.6330275229357798\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4482758620689655]\n",
      "\t[C: 0.001, accuracy: 0.4482758620689655]\n",
      "\t[C: 0.01, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.1, accuracy: 0.4827586206896552]\n",
      "\t[C: 1, accuracy: 0.4827586206896552]\n",
      "\t[C: 10, accuracy: 0.4942528735632184]\n",
      "\t[C: 100, accuracy: 0.5747126436781609]\n",
      "\t[C: 1000, accuracy: 0.6206896551724138]\n",
      "\t[C: 10000, accuracy: 0.6436781609195402]\n",
      "\t[C: 100000, accuracy: 0.6551724137931034]\n",
      "\n",
      "\t> Best C: 100000\n",
      "\t> Best training score: 0.6560693641618497\n",
      "\t> Best test score: 0.6976744186046512\n",
      "\t> Best held score: 0.6788990825688074\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4827586206896552]\n",
      "\t[C: 0.001, accuracy: 0.4827586206896552]\n",
      "\t[C: 0.01, accuracy: 0.5172413793103449]\n",
      "\t[C: 0.1, accuracy: 0.5172413793103449]\n",
      "\t[C: 1, accuracy: 0.5287356321839081]\n",
      "\t[C: 10, accuracy: 0.5632183908045977]\n",
      "\t[C: 100, accuracy: 0.6206896551724138]\n",
      "\t[C: 1000, accuracy: 0.6436781609195402]\n",
      "\t[C: 10000, accuracy: 0.6551724137931034]\n",
      "\t[C: 100000, accuracy: 0.6436781609195402]\n",
      "\n",
      "\t> Best C: 10000\n",
      "\t> Best training score: 0.6560693641618497\n",
      "\t> Best test score: 0.6511627906976745\n",
      "\t> Best held score: 0.6238532110091743\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.01, accuracy: 0.5517241379310345]\n",
      "\t[C: 0.1, accuracy: 0.4942528735632184]\n",
      "\t[C: 1, accuracy: 0.5172413793103449]\n",
      "\t[C: 10, accuracy: 0.5402298850574713]\n",
      "\t[C: 100, accuracy: 0.6091954022988506]\n",
      "\t[C: 1000, accuracy: 0.6666666666666666]\n",
      "\t[C: 10000, accuracy: 0.6781609195402298]\n",
      "\t[C: 100000, accuracy: 0.6781609195402298]\n",
      "\n",
      "\t> Best C: 10000\n",
      "\t> Best training score: 0.6705202312138728\n",
      "\t> Best test score: 0.6744186046511628\n",
      "\t> Best held score: 0.6422018348623854\n",
      "\t ----------\n",
      "\t> Best C param : 10000\n",
      "\t> Average training score list: [0.7304347826086957, 0.672463768115942, 0.6560693641618497, 0.6560693641618497, 0.6705202312138728]\n",
      "\t> Average testing score list: [0.6551724137931034, 0.6781609195402298, 0.6976744186046512, 0.6511627906976745, 0.6744186046511628]\n",
      "\t> Average held score list: [0.7247706422018348, 0.6330275229357798, 0.6788990825688074, 0.6238532110091743, 0.6422018348623854]\n",
      "\n",
      "\t> Average training score list: 0.677111502052442\n",
      "\t> Average testing score list: 0.6713178294573644\n",
      "\t> Average held score list: 0.6605504587155963\n",
      "\n",
      "\tConfusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "\t [[22  0  5  0  0  0]\n",
      " [ 0  8 14  0  0  0]\n",
      " [11  1 40  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0]]\n",
      "================================================== X_name ==================================================\n",
      "\t ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[C: 0.0001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.01, accuracy: 0.5747126436781609]\n",
      "\t[C: 0.1, accuracy: 0.7241379310344828]\n",
      "\t[C: 1, accuracy: 0.7816091954022989]\n",
      "\t[C: 10, accuracy: 0.7701149425287356]\n",
      "\t[C: 100, accuracy: 0.7586206896551724]\n",
      "\t[C: 1000, accuracy: 0.7586206896551724]\n",
      "\t[C: 10000, accuracy: 0.7471264367816092]\n",
      "\t[C: 100000, accuracy: 0.7471264367816092]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9072463768115943\n",
      "\t> Best test score: 0.8620689655172413\n",
      "\t> Best held score: 0.8073394495412844\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.41379310344827586]\n",
      "\t[C: 0.001, accuracy: 0.41379310344827586]\n",
      "\t[C: 0.01, accuracy: 0.5172413793103449]\n",
      "\t[C: 0.1, accuracy: 0.6896551724137931]\n",
      "\t[C: 1, accuracy: 0.7931034482758621]\n",
      "\t[C: 10, accuracy: 0.8160919540229885]\n",
      "\t[C: 100, accuracy: 0.7701149425287356]\n",
      "\t[C: 1000, accuracy: 0.7701149425287356]\n",
      "\t[C: 10000, accuracy: 0.7586206896551724]\n",
      "\t[C: 100000, accuracy: 0.7471264367816092]\n",
      "\n",
      "\t> Best C: 10\n",
      "\t> Best training score: 0.927536231884058\n",
      "\t> Best test score: 0.7586206896551724\n",
      "\t> Best held score: 0.7981651376146789\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4482758620689655]\n",
      "\t[C: 0.001, accuracy: 0.4482758620689655]\n",
      "\t[C: 0.01, accuracy: 0.5517241379310345]\n",
      "\t[C: 0.1, accuracy: 0.735632183908046]\n",
      "\t[C: 1, accuracy: 0.8045977011494253]\n",
      "\t[C: 10, accuracy: 0.8160919540229885]\n",
      "\t[C: 100, accuracy: 0.8045977011494253]\n",
      "\t[C: 1000, accuracy: 0.7816091954022989]\n",
      "\t[C: 10000, accuracy: 0.7586206896551724]\n",
      "\t[C: 100000, accuracy: 0.7816091954022989]\n",
      "\n",
      "\t> Best C: 10\n",
      "\t> Best training score: 0.9364161849710982\n",
      "\t> Best test score: 0.7790697674418605\n",
      "\t> Best held score: 0.7798165137614679\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4827586206896552]\n",
      "\t[C: 0.001, accuracy: 0.4827586206896552]\n",
      "\t[C: 0.01, accuracy: 0.5402298850574713]\n",
      "\t[C: 0.1, accuracy: 0.7126436781609196]\n",
      "\t[C: 1, accuracy: 0.8045977011494253]\n",
      "\t[C: 10, accuracy: 0.8045977011494253]\n",
      "\t[C: 100, accuracy: 0.7816091954022989]\n",
      "\t[C: 1000, accuracy: 0.7701149425287356]\n",
      "\t[C: 10000, accuracy: 0.735632183908046]\n",
      "\t[C: 100000, accuracy: 0.7471264367816092]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9104046242774566\n",
      "\t> Best test score: 0.8023255813953488\n",
      "\t> Best held score: 0.7798165137614679\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.01, accuracy: 0.6551724137931034]\n",
      "\t[C: 0.1, accuracy: 0.735632183908046]\n",
      "\t[C: 1, accuracy: 0.7931034482758621]\n",
      "\t[C: 10, accuracy: 0.7931034482758621]\n",
      "\t[C: 100, accuracy: 0.7471264367816092]\n",
      "\t[C: 1000, accuracy: 0.7011494252873564]\n",
      "\t[C: 10000, accuracy: 0.6896551724137931]\n",
      "\t[C: 100000, accuracy: 0.6666666666666666]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9190751445086706\n",
      "\t> Best test score: 0.7674418604651163\n",
      "\t> Best held score: 0.7889908256880734\n",
      "\t ----------\n",
      "\t> Best C param : 1\n",
      "\t> Average training score list: [0.9072463768115943, 0.927536231884058, 0.9364161849710982, 0.9104046242774566, 0.9190751445086706]\n",
      "\t> Average testing score list: [0.8620689655172413, 0.7586206896551724, 0.7790697674418605, 0.8023255813953488, 0.7674418604651163]\n",
      "\t> Average held score list: [0.8073394495412844, 0.7981651376146789, 0.7798165137614679, 0.7798165137614679, 0.7889908256880734]\n",
      "\n",
      "\t> Average training score list: 0.9201357124905755\n",
      "\t> Average testing score list: 0.7939053728949479\n",
      "\t> Average held score list: 0.7908256880733945\n",
      "\n",
      "\tConfusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "\t [[24  0  3  0  0  0]\n",
      " [ 1 14  6  0  0  1]\n",
      " [ 2  1 46  1  1  1]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  1  4  0  0  0]]\n",
      "================================================== X_stats, X_name ==================================================\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.01, accuracy: 0.6781609195402298]\n",
      "\t[C: 0.1, accuracy: 0.7471264367816092]\n",
      "\t[C: 1, accuracy: 0.8045977011494253]\n",
      "\t[C: 10, accuracy: 0.7701149425287356]\n",
      "\t[C: 100, accuracy: 0.7931034482758621]\n",
      "\t[C: 1000, accuracy: 0.7816091954022989]\n",
      "\t[C: 10000, accuracy: 0.7816091954022989]\n",
      "\t[C: 100000, accuracy: 0.7701149425287356]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9217391304347826\n",
      "\t> Best test score: 0.8505747126436781\n",
      "\t> Best held score: 0.8256880733944955\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.41379310344827586]\n",
      "\t[C: 0.001, accuracy: 0.41379310344827586]\n",
      "\t[C: 0.01, accuracy: 0.6091954022988506]\n",
      "\t[C: 0.1, accuracy: 0.7471264367816092]\n",
      "\t[C: 1, accuracy: 0.7816091954022989]\n",
      "\t[C: 10, accuracy: 0.7931034482758621]\n",
      "\t[C: 100, accuracy: 0.7816091954022989]\n",
      "\t[C: 1000, accuracy: 0.7931034482758621]\n",
      "\t[C: 10000, accuracy: 0.7586206896551724]\n",
      "\t[C: 100000, accuracy: 0.735632183908046]\n",
      "\n",
      "\t> Best C: 10\n",
      "\t> Best training score: 0.927536231884058\n",
      "\t> Best test score: 0.7816091954022989\n",
      "\t> Best held score: 0.7981651376146789\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4482758620689655]\n",
      "\t[C: 0.001, accuracy: 0.4482758620689655]\n",
      "\t[C: 0.01, accuracy: 0.6206896551724138]\n",
      "\t[C: 0.1, accuracy: 0.7586206896551724]\n",
      "\t[C: 1, accuracy: 0.8045977011494253]\n",
      "\t[C: 10, accuracy: 0.8045977011494253]\n",
      "\t[C: 100, accuracy: 0.7586206896551724]\n",
      "\t[C: 1000, accuracy: 0.7471264367816092]\n",
      "\t[C: 10000, accuracy: 0.7471264367816092]\n",
      "\t[C: 100000, accuracy: 0.7586206896551724]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9190751445086706\n",
      "\t> Best test score: 0.7674418604651163\n",
      "\t> Best held score: 0.7706422018348624\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4827586206896552]\n",
      "\t[C: 0.001, accuracy: 0.4827586206896552]\n",
      "\t[C: 0.01, accuracy: 0.6551724137931034]\n",
      "\t[C: 0.1, accuracy: 0.7701149425287356]\n",
      "\t[C: 1, accuracy: 0.8390804597701149]\n",
      "\t[C: 10, accuracy: 0.8275862068965517]\n",
      "\t[C: 100, accuracy: 0.7816091954022989]\n",
      "\t[C: 1000, accuracy: 0.7701149425287356]\n",
      "\t[C: 10000, accuracy: 0.7701149425287356]\n",
      "\t[C: 100000, accuracy: 0.735632183908046]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9277456647398844\n",
      "\t> Best test score: 0.8023255813953488\n",
      "\t> Best held score: 0.8256880733944955\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.01, accuracy: 0.7011494252873564]\n",
      "\t[C: 0.1, accuracy: 0.7586206896551724]\n",
      "\t[C: 1, accuracy: 0.8045977011494253]\n",
      "\t[C: 10, accuracy: 0.7816091954022989]\n",
      "\t[C: 100, accuracy: 0.7586206896551724]\n",
      "\t[C: 1000, accuracy: 0.7816091954022989]\n",
      "\t[C: 10000, accuracy: 0.7586206896551724]\n",
      "\t[C: 100000, accuracy: 0.8390804597701149]\n",
      "\n",
      "\t> Best C: 100000\n",
      "\t> Best training score: 0.9595375722543352\n",
      "\t> Best test score: 0.7441860465116279\n",
      "\t> Best held score: 0.7798165137614679\n",
      "\t ----------\n",
      "\t> Best C param : 1\n",
      "\t> Average training score list: [0.9217391304347826, 0.927536231884058, 0.9190751445086706, 0.9277456647398844, 0.9595375722543352]\n",
      "\t> Average testing score list: [0.8505747126436781, 0.7816091954022989, 0.7674418604651163, 0.8023255813953488, 0.7441860465116279]\n",
      "\t> Average held score list: [0.8256880733944955, 0.7981651376146789, 0.7706422018348624, 0.8256880733944955, 0.7798165137614679]\n",
      "\n",
      "\t> Average training score list: 0.9311267487643462\n",
      "\t> Average testing score list: 0.789227479283614\n",
      "\t> Average held score list: 0.8\n",
      "\n",
      "\tConfusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "\t [[23  0  4  0  0  0]\n",
      " [ 4 14  3  0  0  1]\n",
      " [ 3  2 46  0  1  0]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  1  3  0  1  0]]\n",
      "================================================== X_sample1 ==================================================\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.001, accuracy: 0.47126436781609193]\n",
      "\t[C: 0.01, accuracy: 0.5632183908045977]\n",
      "\t[C: 0.1, accuracy: 0.7471264367816092]\n",
      "\t[C: 1, accuracy: 0.7701149425287356]\n",
      "\t[C: 10, accuracy: 0.7701149425287356]\n",
      "\t[C: 100, accuracy: 0.7586206896551724]\n",
      "\t[C: 1000, accuracy: 0.7586206896551724]\n",
      "\t[C: 10000, accuracy: 0.7816091954022989]\n",
      "\t[C: 100000, accuracy: 0.7816091954022989]\n",
      "\n",
      "\t> Best C: 10000\n",
      "\t> Best training score: 0.8869565217391304\n",
      "\t> Best test score: 0.6666666666666666\n",
      "\t> Best held score: 0.8073394495412844\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.01, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.1, accuracy: 0.6666666666666666]\n",
      "\t[C: 1, accuracy: 0.6781609195402298]\n",
      "\t[C: 10, accuracy: 0.6896551724137931]\n",
      "\t[C: 100, accuracy: 0.6896551724137931]\n",
      "\t[C: 1000, accuracy: 0.6781609195402298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[C: 10000, accuracy: 0.6551724137931034]\n",
      "\t[C: 100000, accuracy: 0.6781609195402298]\n",
      "\n",
      "\t> Best C: 10\n",
      "\t> Best training score: 0.8782608695652174\n",
      "\t> Best test score: 0.7816091954022989\n",
      "\t> Best held score: 0.8165137614678899\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.001, accuracy: 0.47126436781609193]\n",
      "\t[C: 0.01, accuracy: 0.5057471264367817]\n",
      "\t[C: 0.1, accuracy: 0.6666666666666666]\n",
      "\t[C: 1, accuracy: 0.6896551724137931]\n",
      "\t[C: 10, accuracy: 0.7011494252873564]\n",
      "\t[C: 100, accuracy: 0.7011494252873564]\n",
      "\t[C: 1000, accuracy: 0.7241379310344828]\n",
      "\t[C: 10000, accuracy: 0.7241379310344828]\n",
      "\t[C: 100000, accuracy: 0.7471264367816092]\n",
      "\n",
      "\t> Best C: 100000\n",
      "\t> Best training score: 0.8641618497109826\n",
      "\t> Best test score: 0.7674418604651163\n",
      "\t> Best held score: 0.8256880733944955\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.001, accuracy: 0.5402298850574713]\n",
      "\t[C: 0.01, accuracy: 0.5862068965517241]\n",
      "\t[C: 0.1, accuracy: 0.7241379310344828]\n",
      "\t[C: 1, accuracy: 0.7241379310344828]\n",
      "\t[C: 10, accuracy: 0.7701149425287356]\n",
      "\t[C: 100, accuracy: 0.735632183908046]\n",
      "\t[C: 1000, accuracy: 0.7471264367816092]\n",
      "\t[C: 10000, accuracy: 0.735632183908046]\n",
      "\t[C: 100000, accuracy: 0.7011494252873564]\n",
      "\n",
      "\t> Best C: 10\n",
      "\t> Best training score: 0.8757225433526011\n",
      "\t> Best test score: 0.7093023255813954\n",
      "\t> Best held score: 0.7798165137614679\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5632183908045977]\n",
      "\t[C: 0.001, accuracy: 0.5862068965517241]\n",
      "\t[C: 0.01, accuracy: 0.6206896551724138]\n",
      "\t[C: 0.1, accuracy: 0.7701149425287356]\n",
      "\t[C: 1, accuracy: 0.7701149425287356]\n",
      "\t[C: 10, accuracy: 0.7931034482758621]\n",
      "\t[C: 100, accuracy: 0.7931034482758621]\n",
      "\t[C: 1000, accuracy: 0.7931034482758621]\n",
      "\t[C: 10000, accuracy: 0.7586206896551724]\n",
      "\t[C: 100000, accuracy: 0.735632183908046]\n",
      "\n",
      "\t> Best C: 10\n",
      "\t> Best training score: 0.884393063583815\n",
      "\t> Best test score: 0.7906976744186046\n",
      "\t> Best held score: 0.8348623853211009\n",
      "\t ----------\n",
      "\t> Best C param : 10\n",
      "\t> Average training score list: [0.8869565217391304, 0.8782608695652174, 0.8641618497109826, 0.8757225433526011, 0.884393063583815]\n",
      "\t> Average testing score list: [0.6666666666666666, 0.7816091954022989, 0.7674418604651163, 0.7093023255813954, 0.7906976744186046]\n",
      "\t> Average held score list: [0.8073394495412844, 0.8165137614678899, 0.8256880733944955, 0.7798165137614679, 0.8348623853211009]\n",
      "\n",
      "\t> Average training score list: 0.8778989695903494\n",
      "\t> Average testing score list: 0.7431435445068164\n",
      "\t> Average held score list: 0.8128440366972477\n",
      "\n",
      "\tConfusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "\t [[24  0  3  0  0  0]\n",
      " [ 0 16  6  0  0  0]\n",
      " [ 2  0 49  0  0  1]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  1  4  0  0  0]]\n",
      "================================================== X_name, X_sample1 ==================================================\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.001, accuracy: 0.47126436781609193]\n",
      "\t[C: 0.01, accuracy: 0.6896551724137931]\n",
      "\t[C: 0.1, accuracy: 0.7701149425287356]\n",
      "\t[C: 1, accuracy: 0.7816091954022989]\n",
      "\t[C: 10, accuracy: 0.7471264367816092]\n",
      "\t[C: 100, accuracy: 0.7241379310344828]\n",
      "\t[C: 1000, accuracy: 0.7241379310344828]\n",
      "\t[C: 10000, accuracy: 0.7241379310344828]\n",
      "\t[C: 100000, accuracy: 0.7586206896551724]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.936231884057971\n",
      "\t> Best test score: 0.7816091954022989\n",
      "\t> Best held score: 0.8532110091743119\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.01, accuracy: 0.6436781609195402]\n",
      "\t[C: 0.1, accuracy: 0.6781609195402298]\n",
      "\t[C: 1, accuracy: 0.735632183908046]\n",
      "\t[C: 10, accuracy: 0.7471264367816092]\n",
      "\t[C: 100, accuracy: 0.7471264367816092]\n",
      "\t[C: 1000, accuracy: 0.7126436781609196]\n",
      "\t[C: 10000, accuracy: 0.7126436781609196]\n",
      "\t[C: 100000, accuracy: 0.6896551724137931]\n",
      "\n",
      "\t> Best C: 10\n",
      "\t> Best training score: 0.9304347826086956\n",
      "\t> Best test score: 0.8045977011494253\n",
      "\t> Best held score: 0.8165137614678899\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.001, accuracy: 0.47126436781609193]\n",
      "\t[C: 0.01, accuracy: 0.632183908045977]\n",
      "\t[C: 0.1, accuracy: 0.735632183908046]\n",
      "\t[C: 1, accuracy: 0.7816091954022989]\n",
      "\t[C: 10, accuracy: 0.7586206896551724]\n",
      "\t[C: 100, accuracy: 0.7011494252873564]\n",
      "\t[C: 1000, accuracy: 0.6781609195402298]\n",
      "\t[C: 10000, accuracy: 0.6896551724137931]\n",
      "\t[C: 100000, accuracy: 0.7241379310344828]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.930635838150289\n",
      "\t> Best test score: 0.813953488372093\n",
      "\t> Best held score: 0.8348623853211009\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.001, accuracy: 0.5402298850574713]\n",
      "\t[C: 0.01, accuracy: 0.6896551724137931]\n",
      "\t[C: 0.1, accuracy: 0.7816091954022989]\n",
      "\t[C: 1, accuracy: 0.8045977011494253]\n",
      "\t[C: 10, accuracy: 0.8045977011494253]\n",
      "\t[C: 100, accuracy: 0.735632183908046]\n",
      "\t[C: 1000, accuracy: 0.7126436781609196]\n",
      "\t[C: 10000, accuracy: 0.7241379310344828]\n",
      "\t[C: 100000, accuracy: 0.7126436781609196]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9393063583815029\n",
      "\t> Best test score: 0.8372093023255814\n",
      "\t> Best held score: 0.8256880733944955\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5632183908045977]\n",
      "\t[C: 0.001, accuracy: 0.5862068965517241]\n",
      "\t[C: 0.01, accuracy: 0.735632183908046]\n",
      "\t[C: 0.1, accuracy: 0.8160919540229885]\n",
      "\t[C: 1, accuracy: 0.8620689655172413]\n",
      "\t[C: 10, accuracy: 0.8505747126436781]\n",
      "\t[C: 100, accuracy: 0.7586206896551724]\n",
      "\t[C: 1000, accuracy: 0.7586206896551724]\n",
      "\t[C: 10000, accuracy: 0.7241379310344828]\n",
      "\t[C: 100000, accuracy: 0.735632183908046]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.953757225433526\n",
      "\t> Best test score: 0.813953488372093\n",
      "\t> Best held score: 0.8256880733944955\n",
      "\t ----------\n",
      "\t> Best C param : 1\n",
      "\t> Average training score list: [0.936231884057971, 0.9304347826086956, 0.930635838150289, 0.9393063583815029, 0.953757225433526]\n",
      "\t> Average testing score list: [0.7816091954022989, 0.8045977011494253, 0.813953488372093, 0.8372093023255814, 0.813953488372093]\n",
      "\t> Average held score list: [0.8532110091743119, 0.8165137614678899, 0.8348623853211009, 0.8256880733944955, 0.8256880733944955]\n",
      "\n",
      "\t> Average training score list: 0.9380732177263968\n",
      "\t> Average testing score list: 0.8102646351242984\n",
      "\t> Average held score list: 0.8311926605504587\n",
      "\n",
      "\tConfusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "\t [[25  0  2  0  0  0]\n",
      " [ 0 15  7  0  0  0]\n",
      " [ 2  1 48  0  0  1]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  1  4  0  0  0]]\n",
      "================================================== X_stats, X_sample1 ==================================================\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.001, accuracy: 0.47126436781609193]\n",
      "\t[C: 0.01, accuracy: 0.6436781609195402]\n",
      "\t[C: 0.1, accuracy: 0.7241379310344828]\n",
      "\t[C: 1, accuracy: 0.7241379310344828]\n",
      "\t[C: 10, accuracy: 0.735632183908046]\n",
      "\t[C: 100, accuracy: 0.735632183908046]\n",
      "\t[C: 1000, accuracy: 0.7471264367816092]\n",
      "\t[C: 10000, accuracy: 0.7931034482758621]\n",
      "\t[C: 100000, accuracy: 0.8160919540229885]\n",
      "\n",
      "\t> Best C: 100000\n",
      "\t> Best training score: 0.9333333333333333\n",
      "\t> Best test score: 0.7701149425287356\n",
      "\t> Best held score: 0.7431192660550459\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.01, accuracy: 0.5977011494252874]\n",
      "\t[C: 0.1, accuracy: 0.6551724137931034]\n",
      "\t[C: 1, accuracy: 0.6551724137931034]\n",
      "\t[C: 10, accuracy: 0.6436781609195402]\n",
      "\t[C: 100, accuracy: 0.6551724137931034]\n",
      "\t[C: 1000, accuracy: 0.6436781609195402]\n",
      "\t[C: 10000, accuracy: 0.5862068965517241]\n",
      "\t[C: 100000, accuracy: 0.5862068965517241]\n",
      "\n",
      "\t> Best C: 0.1\n",
      "\t> Best training score: 0.8347826086956521\n",
      "\t> Best test score: 0.7586206896551724\n",
      "\t> Best held score: 0.7889908256880734\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.001, accuracy: 0.47126436781609193]\n",
      "\t[C: 0.01, accuracy: 0.6206896551724138]\n",
      "\t[C: 0.1, accuracy: 0.6666666666666666]\n",
      "\t[C: 1, accuracy: 0.6206896551724138]\n",
      "\t[C: 10, accuracy: 0.6551724137931034]\n",
      "\t[C: 100, accuracy: 0.6206896551724138]\n",
      "\t[C: 1000, accuracy: 0.6666666666666666]\n",
      "\t[C: 10000, accuracy: 0.7011494252873564]\n",
      "\t[C: 100000, accuracy: 0.7241379310344828]\n",
      "\n",
      "\t> Best C: 100000\n",
      "\t> Best training score: 0.9104046242774566\n",
      "\t> Best test score: 0.6744186046511628\n",
      "\t> Best held score: 0.6972477064220184\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.001, accuracy: 0.5402298850574713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[C: 0.01, accuracy: 0.6781609195402298]\n",
      "\t[C: 0.1, accuracy: 0.7586206896551724]\n",
      "\t[C: 1, accuracy: 0.7126436781609196]\n",
      "\t[C: 10, accuracy: 0.6436781609195402]\n",
      "\t[C: 100, accuracy: 0.6666666666666666]\n",
      "\t[C: 1000, accuracy: 0.6436781609195402]\n",
      "\t[C: 10000, accuracy: 0.6091954022988506]\n",
      "\t[C: 100000, accuracy: 0.7011494252873564]\n",
      "\n",
      "\t> Best C: 0.1\n",
      "\t> Best training score: 0.8352601156069365\n",
      "\t> Best test score: 0.686046511627907\n",
      "\t> Best held score: 0.7798165137614679\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5632183908045977]\n",
      "\t[C: 0.001, accuracy: 0.5862068965517241]\n",
      "\t[C: 0.01, accuracy: 0.7011494252873564]\n",
      "\t[C: 0.1, accuracy: 0.735632183908046]\n",
      "\t[C: 1, accuracy: 0.7126436781609196]\n",
      "\t[C: 10, accuracy: 0.6666666666666666]\n",
      "\t[C: 100, accuracy: 0.6551724137931034]\n",
      "\t[C: 1000, accuracy: 0.6551724137931034]\n",
      "\t[C: 10000, accuracy: 0.6666666666666666]\n",
      "\t[C: 100000, accuracy: 0.7701149425287356]\n",
      "\n",
      "\t> Best C: 100000\n",
      "\t> Best training score: 0.9161849710982659\n",
      "\t> Best test score: 0.813953488372093\n",
      "\t> Best held score: 0.6788990825688074\n",
      "\t ----------\n",
      "\t> Best C param : 100000\n",
      "\t> Average training score list: [0.9333333333333333, 0.8347826086956521, 0.9104046242774566, 0.8352601156069365, 0.9161849710982659]\n",
      "\t> Average testing score list: [0.7701149425287356, 0.7586206896551724, 0.6744186046511628, 0.686046511627907, 0.813953488372093]\n",
      "\t> Average held score list: [0.7431192660550459, 0.7889908256880734, 0.6972477064220184, 0.7798165137614679, 0.6788990825688074]\n",
      "\n",
      "\t> Average training score list: 0.8859931306023288\n",
      "\t> Average testing score list: 0.7406308473670141\n",
      "\t> Average held score list: 0.7376146788990826\n",
      "\n",
      "\tConfusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "\t [[26  0  1  0  0  0]\n",
      " [ 0 14  7  1  0  0]\n",
      " [ 3  8 32  7  1  1]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  2  2  1  0  0]]\n",
      "================================================== X_stats, X_name, X_sample1 ==================================================\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.001, accuracy: 0.47126436781609193]\n",
      "\t[C: 0.01, accuracy: 0.7011494252873564]\n",
      "\t[C: 0.1, accuracy: 0.7586206896551724]\n",
      "\t[C: 1, accuracy: 0.7816091954022989]\n",
      "\t[C: 10, accuracy: 0.7931034482758621]\n",
      "\t[C: 100, accuracy: 0.7931034482758621]\n",
      "\t[C: 1000, accuracy: 0.7701149425287356]\n",
      "\t[C: 10000, accuracy: 0.7931034482758621]\n",
      "\t[C: 100000, accuracy: 0.7931034482758621]\n",
      "\n",
      "\t> Best C: 10\n",
      "\t> Best training score: 0.9478260869565217\n",
      "\t> Best test score: 0.7701149425287356\n",
      "\t> Best held score: 0.8256880733944955\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.4367816091954023]\n",
      "\t[C: 0.001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.01, accuracy: 0.6436781609195402]\n",
      "\t[C: 0.1, accuracy: 0.7126436781609196]\n",
      "\t[C: 1, accuracy: 0.7586206896551724]\n",
      "\t[C: 10, accuracy: 0.7471264367816092]\n",
      "\t[C: 100, accuracy: 0.735632183908046]\n",
      "\t[C: 1000, accuracy: 0.7011494252873564]\n",
      "\t[C: 10000, accuracy: 0.5632183908045977]\n",
      "\t[C: 100000, accuracy: 0.5517241379310345]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9304347826086956\n",
      "\t> Best test score: 0.8045977011494253\n",
      "\t> Best held score: 0.8440366972477065\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.45977011494252873]\n",
      "\t[C: 0.001, accuracy: 0.47126436781609193]\n",
      "\t[C: 0.01, accuracy: 0.6436781609195402]\n",
      "\t[C: 0.1, accuracy: 0.735632183908046]\n",
      "\t[C: 1, accuracy: 0.7701149425287356]\n",
      "\t[C: 10, accuracy: 0.7241379310344828]\n",
      "\t[C: 100, accuracy: 0.7011494252873564]\n",
      "\t[C: 1000, accuracy: 0.7126436781609196]\n",
      "\t[C: 10000, accuracy: 0.5977011494252874]\n",
      "\t[C: 100000, accuracy: 0.5747126436781609]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9277456647398844\n",
      "\t> Best test score: 0.813953488372093\n",
      "\t> Best held score: 0.8073394495412844\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5287356321839081]\n",
      "\t[C: 0.001, accuracy: 0.5402298850574713]\n",
      "\t[C: 0.01, accuracy: 0.7126436781609196]\n",
      "\t[C: 0.1, accuracy: 0.7816091954022989]\n",
      "\t[C: 1, accuracy: 0.8275862068965517]\n",
      "\t[C: 10, accuracy: 0.7701149425287356]\n",
      "\t[C: 100, accuracy: 0.7701149425287356]\n",
      "\t[C: 1000, accuracy: 0.7241379310344828]\n",
      "\t[C: 10000, accuracy: 0.5632183908045977]\n",
      "\t[C: 100000, accuracy: 0.5747126436781609]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9450867052023122\n",
      "\t> Best test score: 0.8255813953488372\n",
      "\t> Best held score: 0.8073394495412844\n",
      "\t ----------\n",
      "\t[C: 0.0001, accuracy: 0.5632183908045977]\n",
      "\t[C: 0.001, accuracy: 0.5862068965517241]\n",
      "\t[C: 0.01, accuracy: 0.735632183908046]\n",
      "\t[C: 0.1, accuracy: 0.8160919540229885]\n",
      "\t[C: 1, accuracy: 0.8620689655172413]\n",
      "\t[C: 10, accuracy: 0.8045977011494253]\n",
      "\t[C: 100, accuracy: 0.8045977011494253]\n",
      "\t[C: 1000, accuracy: 0.7931034482758621]\n",
      "\t[C: 10000, accuracy: 0.7931034482758621]\n",
      "\t[C: 100000, accuracy: 0.8045977011494253]\n",
      "\n",
      "\t> Best C: 1\n",
      "\t> Best training score: 0.9566473988439307\n",
      "\t> Best test score: 0.8023255813953488\n",
      "\t> Best held score: 0.8256880733944955\n",
      "\t ----------\n",
      "\t> Best C param : 1\n",
      "\t> Average training score list: [0.9478260869565217, 0.9304347826086956, 0.9277456647398844, 0.9450867052023122, 0.9566473988439307]\n",
      "\t> Average testing score list: [0.7701149425287356, 0.8045977011494253, 0.813953488372093, 0.8255813953488372, 0.8023255813953488]\n",
      "\t> Average held score list: [0.8256880733944955, 0.8440366972477065, 0.8073394495412844, 0.8073394495412844, 0.8256880733944955]\n",
      "\n",
      "\t> Average training score list: 0.9415481276702689\n",
      "\t> Average testing score list: 0.803314621758888\n",
      "\t> Average held score list: 0.8220183486238533\n",
      "\n",
      "\tConfusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "\t [[24  0  3  0  0  0]\n",
      " [ 0 16  6  0  0  0]\n",
      " [ 1  2 48  0  0  1]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  1  4  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test_feat_combos(index)\n",
    "acc_df.to_csv('data/model_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
