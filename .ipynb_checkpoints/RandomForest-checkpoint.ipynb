{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#Copyright 2019 Vraj Shah, Arun Kumar\n",
    "#\n",
    "#Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#you may not use this file except in compliance with the License.\n",
    "#You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#Unless required by applicable law or agreed to in writing, software\n",
    "#distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#See the License for the specific language governing permissions and\n",
    "#limitations under the License.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "# import enchant\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "# from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import enchant\n",
    "np.random.seed(512)\n",
    "# import subprocess\n",
    "# subprocess.call([\"pip\",\"install\", \"pyenchant\",\"--\",\"user\"])\n",
    "# os.system('pip install pyenchant')\n",
    "# import nltk\n",
    "# from nltk.corpus import words\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (2,5,10,11,12,13,14,15,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#read csv\n",
    "dict_label = {'Usable directly numeric':0, 'Usable with extraction':1, 'Usable with Extration': 1, 'Usable with extraction ':1, 'Usable directly categorical':2, 'Unusable':3, 'Context_specific':4, 'Usable directly categorical ':2}\n",
    "data = pd.read_csv('data_for_ML_num.csv')\n",
    "\n",
    "data['y_act'] = [dict_label[i] for i in data['y_act']]\n",
    "y = data.loc[:,['y_act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Num of nans'] = [data['Num of nans'][i]*100/data['Total_val'][i] for i in data.index]\n",
    "data['num of dist_val'] = [data['num of dist_val'][i]*100/data['Total_val'][i] for i in data.index]\n",
    "\n",
    "data1 = data[['Num of nans', 'max_val', 'mean', 'min_val', 'num of dist_val','std_dev','castability','extractability', 'len_val']]\n",
    "data1 = data1.fillna(0)\n",
    "\n",
    "# data = data.rename(columns={'mean': 'scaled_mean', 'min_val': 'scaled_min_val', 'max_val': 'scaled_max_val','std_dev': 'scaled_std_dev','len_val': 'scaled_len_val'})\n",
    "# column_names_to_normalize = ['scaled_max_val', 'scaled_mean', 'scaled_min_val','scaled_std_dev', 'scaled_len_val']\n",
    "# x = data[column_names_to_normalize].values\n",
    "# x = np.nan_to_num(x)\n",
    "# x_scaled = StandardScaler().fit_transform(x)\n",
    "# df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = data.index)\n",
    "# data[column_names_to_normalize] = df_temp\n",
    "\n",
    "# X_train, X_test,y_train,y_test = train_test_split(data,y, test_size=0.2)\n",
    "\n",
    "# new_data = data[['scaled_min_val']]\n",
    "# new_data.scaled_min_val = new_data.scaled_min_val.astype(float)\n",
    "# normalized_df=(new_data-new_data.mean())/new_data.std()\n",
    "# new_data = new_data[np.abs(new_data.scaled_min_val-new_data.scaled_min_val.mean()) <= (3*new_data.scaled_min_val.std())]\n",
    "\n",
    "# for index, row in new_data.iterrows():\n",
    "#     if row['scaled_min_val'] > 100000:\n",
    "#         new_data.iloc[index]['scaled_min_val'] = 100000\n",
    "#     if row['scaled_min_val'] < -100000:\n",
    "#         new_data.iloc[index]['scaled_min_val'] = -100000        \n",
    "#     print(row['scaled_min_val']) \n",
    "\n",
    "# q = new_data['scaled_min_val'].quantile(0.99)\n",
    "# new_data = new_data[new_data['scaled_min_val'] < q]\n",
    "# print(new_data)\n",
    "\n",
    "# print(new_data.mean())\n",
    "# print(new_data.std())\n",
    "\n",
    "\n",
    "# scaled_features = StandardScaler().fit_transform(new_data.values)\n",
    "# df = pd.DataFrame(scaled_features)\n",
    "# scaled_features = MinMaxScaler().fit_transform(new_data.values)\n",
    "# df = pd.DataFrame(scaled_features)\n",
    "\n",
    "# std_scale = preprocessing.StandardScaler().fit(data[['max_val', 'min_val']])\n",
    "# data = std_scale.transform(data[['max_val', 'min_val']])\n",
    "# data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1.to_csv('before.csv')\n",
    "# f = open('current.txt','w')\n",
    "d = enchant.Dict(\"en_US\")\n",
    "\n",
    "for i in data.index:\n",
    "    ival = data.at[i,'Attribute_name']\n",
    "    if ival != 'id' and d.check(ival):\n",
    "#         print >> f,ival\n",
    "#         print >> f,y.at[i,'y_act']\n",
    "        data1.at[i,'dictionary_item'] = 1\n",
    "    else:\n",
    "        data1.at[i,'dictionary_item'] = 0\n",
    "\n",
    "# data1.to_csv('after.csv')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6360\n"
     ]
    }
   ],
   "source": [
    "# print(data1.columns)\n",
    "\n",
    "arr = data['Attribute_name'].values\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(3,3),analyzer='char')\n",
    "X = vectorizer.fit_transform(arr)\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "# print(X.toarray())\n",
    "\n",
    "# data1.to_csv('before.csv')\n",
    "\n",
    "tempdf = pd.DataFrame(X.toarray())\n",
    "\n",
    "data2 = pd.concat([data1,tempdf], axis=1, sort=False)\n",
    "\n",
    "# data2.to_csv('after.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:36: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9673986486486487\n",
      "0.8891891891891892\n",
      "0.8951917882225824\n",
      "0.9682432432432433\n",
      "0.8695945945945946\n",
      "0.8876283090221502\n",
      "0.9702702702702702\n",
      "0.8959459459459459\n",
      "0.8946515397082658\n",
      "0.9721283783783784\n",
      "0.8871621621621621\n",
      "0.8984332793084819\n",
      "0.9706081081081082\n",
      "0.8864864864864865\n",
      "0.8935710426796326\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(data2,y, test_size=0.2,random_state=100)\n",
    "print(len(X_train))\n",
    "data2 = data2.rename(columns={'mean': 'scaled_mean', 'min_val': 'scaled_min_val', 'max_val': 'scaled_max_val','std_dev': 'scaled_std_dev'})\n",
    "\n",
    "\n",
    "X_train_new = X_train.reset_index(drop=True)\n",
    "y_train_new = y_train.reset_index(drop=True)\n",
    "# print(X_train.head())\n",
    "# print(y_train.head())\n",
    "\n",
    "X_train_new = X_train_new.values\n",
    "y_train_new = y_train_new.values\n",
    "# print(X_train_new)\n",
    "# print(y_train_new)\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "avg_train_acc,avg_test_acc = 0,0\n",
    "    \n",
    "n_estimators_grid = [5,25,50,75,100]\n",
    "max_depth_grid = [5,10,25,50,100]\n",
    "\n",
    "avgsc_lst,avgsc_train_lst,avgsc_hld_lst = [],[],[]\n",
    "avgsc,avgsc_train,avgsc_hld = 0,0,0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_new):\n",
    "    X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "    y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "    X_train_train, X_val,y_train_train,y_val = train_test_split(X_train_cur,y_train_cur, test_size=0.25,random_state=100)\n",
    "    \n",
    "    bestPerformingModel = RandomForestClassifier(n_estimators=10,max_depth=5)\n",
    "    bestscore = 0\n",
    "    for ne in n_estimators_grid:\n",
    "        for md in max_depth_grid:\n",
    "            clf = RandomForestClassifier(n_estimators=ne,max_depth=md)\n",
    "            clf.fit(X_train_train, y_train_train)\n",
    "            sc = clf.score(X_val, y_val)\n",
    "    \n",
    "            if bestscore < sc:\n",
    "                bestscore = sc\n",
    "                bestPerformingModel = clf\n",
    "#                 print(bestPerformingModel)\n",
    "\n",
    "    bscr_train = bestPerformingModel.score(X_train_cur, y_train_cur)\n",
    "    bscr = bestPerformingModel.score(X_test_cur, y_test_cur)\n",
    "    bscr_hld = bestPerformingModel.score(X_test, y_test)\n",
    "\n",
    "    avgsc_train_lst.append(bscr_train)\n",
    "    avgsc_lst.append(bscr)\n",
    "    avgsc_hld_lst.append(bscr_hld)\n",
    "    \n",
    "    avgsc_train = avgsc_train + bscr_train    \n",
    "    avgsc = avgsc + bscr\n",
    "    avgsc_hld = avgsc_hld + bscr_hld\n",
    "\n",
    "    print(bscr_train)\n",
    "    print(bscr)\n",
    "    print(bscr_hld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9673986486486487, 0.9682432432432433, 0.9702702702702702, 0.9721283783783784, 0.9706081081081082]\n",
      "[0.8891891891891892, 0.8695945945945946, 0.8959459459459459, 0.8871621621621621, 0.8864864864864865]\n",
      "[0.8951917882225824, 0.8876283090221502, 0.8946515397082658, 0.8984332793084819, 0.8935710426796326]\n",
      "0.9697297297297297\n",
      "0.8856756756756756\n",
      "0.8938951917882226\n",
      "Confusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "[[676   1  10   1  18]\n",
      " [  2 114  22   0   5]\n",
      " [  5  11 403   2  10]\n",
      " [  4   6  24 124   9]\n",
      " [ 31   7  27   2 337]]\n"
     ]
    }
   ],
   "source": [
    "print(avgsc_train_lst)\n",
    "print(avgsc_lst)\n",
    "print(avgsc_hld_lst)\n",
    "\n",
    "print(avgsc_train/k)\n",
    "print(avgsc/k)\n",
    "print(avgsc_hld/k)\n",
    "\n",
    "\n",
    "y_pred = bestPerformingModel.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix: Actual (Row) vs Predicted (Column)')\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(bestPerformingModel, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.10000000e-01 0.00000000e+00 6.00000000e-02 2.00000000e-02\n",
      "  1.00000000e-02]\n",
      " [9.90000000e-01 0.00000000e+00 1.00000000e-02 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [7.86558374e-04 6.99908823e-03 3.68930132e-01 2.28337037e-02\n",
      "  6.00450518e-01]\n",
      " ...\n",
      " [3.94082665e-03 1.15635360e-03 9.80824622e-01 5.08787981e-03\n",
      "  8.99031757e-03]\n",
      " [9.23341025e-01 2.30734513e-04 9.52463223e-03 1.41985355e-02\n",
      "  5.27050729e-02]\n",
      " [2.49273211e-01 2.01553437e-02 3.74436179e-01 4.04372814e-02\n",
      "  3.15697985e-01]]\n",
      "             0         1         2         3         4\n",
      "0     0.910000  0.000000  0.060000  0.020000  0.010000\n",
      "1     0.990000  0.000000  0.010000  0.000000  0.000000\n",
      "2     0.000787  0.006999  0.368930  0.022834  0.600451\n",
      "3     0.925181  0.010000  0.030000  0.000909  0.033910\n",
      "4     0.010952  0.261055  0.605574  0.040027  0.082392\n",
      "5     0.715627  0.000397  0.042645  0.011066  0.230264\n",
      "6     0.411036  0.000087  0.477958  0.001725  0.109193\n",
      "7     0.040000  0.050000  0.000000  0.020000  0.890000\n",
      "8     0.155962  0.418335  0.172722  0.145969  0.107013\n",
      "9     0.989484  0.000000  0.001254  0.000407  0.008855\n",
      "10    0.057978  0.000143  0.933792  0.001725  0.006362\n",
      "11    0.000000  0.023462  0.038079  0.926201  0.012258\n",
      "12    0.007846  0.012075  0.111514  0.853336  0.015228\n",
      "13    0.987938  0.000000  0.010232  0.000593  0.001237\n",
      "14    0.954545  0.000000  0.020000  0.000000  0.025455\n",
      "15    0.480089  0.000000  0.020750  0.003160  0.496002\n",
      "16    0.073259  0.669983  0.111503  0.047203  0.098051\n",
      "17    0.669572  0.000725  0.072648  0.102344  0.154712\n",
      "18    0.000228  0.007189  0.912626  0.075111  0.004847\n",
      "19    0.319705  0.000139  0.094465  0.043011  0.542679\n",
      "20    0.185840  0.000582  0.026508  0.647021  0.140050\n",
      "21    0.013675  0.249720  0.616414  0.066145  0.054045\n",
      "22    0.338716  0.000418  0.072946  0.151867  0.436051\n",
      "23    1.000000  0.000000  0.000000  0.000000  0.000000\n",
      "24    0.000157  0.001218  0.994409  0.002945  0.001271\n",
      "25    0.980000  0.000000  0.000000  0.010000  0.010000\n",
      "26    0.990000  0.000000  0.010000  0.000000  0.000000\n",
      "27    0.012246  0.031335  0.629773  0.307701  0.018945\n",
      "28    0.105391  0.182157  0.446349  0.123623  0.142480\n",
      "29    0.349384  0.052420  0.316174  0.064321  0.217700\n",
      "...        ...       ...       ...       ...       ...\n",
      "1821  0.181442  0.520382  0.015582  0.074626  0.207968\n",
      "1822  0.002237  0.103014  0.595483  0.148097  0.151169\n",
      "1823  0.566984  0.070000  0.295463  0.021278  0.046276\n",
      "1824  0.178575  0.000000  0.027997  0.040191  0.753237\n",
      "1825  0.985388  0.000000  0.000664  0.000407  0.013541\n",
      "1826  0.074915  0.000000  0.019868  0.190132  0.715085\n",
      "1827  0.020937  0.182792  0.601557  0.136676  0.058039\n",
      "1828  1.000000  0.000000  0.000000  0.000000  0.000000\n",
      "1829  0.071304  0.000000  0.050000  0.350000  0.528696\n",
      "1830  0.950000  0.000000  0.000000  0.050000  0.000000\n",
      "1831  0.012639  0.002668  0.946883  0.008155  0.029655\n",
      "1832  0.866858  0.020139  0.024050  0.031492  0.057461\n",
      "1833  0.894372  0.000000  0.030717  0.000593  0.074318\n",
      "1834  0.097908  0.000174  0.767305  0.007858  0.126755\n",
      "1835  0.809623  0.000477  0.044322  0.017179  0.128399\n",
      "1836  0.990000  0.000000  0.000000  0.000000  0.010000\n",
      "1837  0.992182  0.000000  0.001274  0.002419  0.004124\n",
      "1838  0.007846  0.012075  0.111514  0.853336  0.015228\n",
      "1839  1.000000  0.000000  0.000000  0.000000  0.000000\n",
      "1840  0.003151  0.055362  0.830132  0.070175  0.041180\n",
      "1841  0.000556  0.000000  0.998259  0.000000  0.001185\n",
      "1842  0.418620  0.014319  0.397615  0.016693  0.152752\n",
      "1843  0.030559  0.345135  0.542587  0.078094  0.003625\n",
      "1844  0.000864  0.000000  0.000000  0.000000  0.999136\n",
      "1845  0.172007  0.255832  0.451521  0.079049  0.041592\n",
      "1846  0.649439  0.000473  0.082088  0.024748  0.243252\n",
      "1847  0.901028  0.010087  0.022995  0.011702  0.054187\n",
      "1848  0.003941  0.001156  0.980825  0.005088  0.008990\n",
      "1849  0.923341  0.000231  0.009525  0.014199  0.052705\n",
      "1850  0.249273  0.020155  0.374436  0.040437  0.315698\n",
      "\n",
      "[1851 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "y_prob = bestPerformingModel.predict_proba(X_test)\n",
    "print(y_prob)\n",
    "\n",
    "df = DataFrame.from_records(y_prob)\n",
    "print(df)\n",
    "df.to_csv('rf_predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
